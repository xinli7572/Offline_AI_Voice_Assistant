

#  Offline AI Voice Assistant Prototype 
#  Java springboot/Android --> C++ Backend


https://github.com/user-attachments/assets/8470d2bd-a5ef-403f-8369-0f5a830b5a53



> ğŸ™ï¸ This project is a prototype of an **offline AI voice assistant**, featuring three locally-deployed AI components:
> - **Speech Recognition (STT)** using Vosk,
> - **Language Modeling (LLM)** using TinyLLaMA via llama.cpp,
> - **Text-to-Speech (TTS)** using Piper.

It also includes **Java-based Web and Android clients**, both communicating with the C++ backend through sockets.

---

## âœ… Current Project Status

The project includes:

| Component            | Description                                                   | Status       |
|----------------------|---------------------------------------------------------------|--------------|
| ğŸ§  **TinyLLaMA**      | Lightweight language model via llama.cpp (C++ wrapper)         | âœ… Tested     |
| ğŸ—£ï¸ **Vosk**          | Offline speech recognition engine (C++ interface)             | âœ… Tested     |
| ğŸ”Š **Piper**         | Local text-to-speech engine using ONNX models (C++ interface) | âœ… Tested     |
| ğŸŒ **Java Web UI**   | HTML + JS browser-based frontend with socket communication    | âœ… Functional |
| ğŸ“± **Android Client**| Native Android app using socket communication                 | âœ… Functional |
| âš™ï¸ **Install Scripts**| Individual setup scripts and test code for each model         | âœ… Provided   |

> Each model is **tested individually** with standalone C++ test programs.

---

## ğŸ“¦ Project Structure
```
offline-voice-ai/
â”œâ”€â”€ models/ # Model directories (downloaded via scripts)
â”‚ â”œâ”€â”€ vosk/
â”‚ â”œâ”€â”€ piper/
â”‚ â””â”€â”€ tinyllama/
â”œâ”€â”€ cpp-tests/ # C++ test programs for each model
â”‚ â”œâ”€â”€ vosk_test.cpp
â”‚ â”œâ”€â”€ llama_test.cpp
â”‚ â””â”€â”€ piper_test.cpp
â”œâ”€â”€ java-web/ # Java-based Web UI (HTML + WebSocket)
â”‚ â”œâ”€â”€ index.html
â”‚ â””â”€â”€ ...
â”œâ”€â”€ android-client/ # Android client (native Java/Kotlin)
â”‚ â””â”€â”€ app/
â”œâ”€â”€ setup/ # Shell scripts for model installation (written by author)
â”‚ â”œâ”€â”€ install_vosk.sh
â”‚ â”œâ”€â”€ install_piper.sh
â”‚ â””â”€â”€ install_llama.sh
â”œâ”€â”€ README.md
â””â”€â”€ docs/ # Documentation and screenshots
```


---

## ğŸ“‹ C++ Model Test Instructions

###  1. Vosk STT Test

```bash
cd cpp-tests
g++ -std=c++17 -lstdc++ -Wall  -I/usr/src/vosk_stt/include  -c main.cpp -o main.o
g++ -std=c++17  -lstdc++ -o vosks main.o  -L/usr/src/vosk_stt/lib  -lvosk -Wl,--copy-dt-needed-entries -Wl,-rpath=/usr/src/vosk_stt/lib -lm -lpthread -ldl  /usr/lib/x86_64-linux-gnu/libpthread.a

```
Output: Recognized text from audio.

### 2. TinyLLaMA LLM Test

```bash
cd cpp-tests
	./llama-cli \
	  -m /usr/src/llama.cpp/build/bin/tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf\
	  --temp 0.6 \
	  --top-k 20 \
	  --top-p 0.5 \
	  --repeat-penalty 1.2
```
Output: AI-generated response.

### 3. Piper TTS Test

```bash
cd cpp-tests
g++ -std=c++17 -lstdc++ -Wall  -I/usr/src/piper_tts/cpp -I/usr/src/piper_tts/pi/include  -c main.cpp -o main.o
g++ -std=c++17 -lstdc++ -Wall  -I/usr/src/piper_tts/cpp -I/usr/src/piper_tts/pi/include  -c piper.cpp -o piper.o
g++ -std=c++17  -lstdc++ -o pipers main.o piper.o -L/usr/src/piper_tts/pi/lib  -lonnxruntime -lpiper_phonemize -lespeak-ng -Wl,--copy-dt-needed-entries -Wl,-rpath=/usr/src/piper_tts/pi/lib -lm -lpthread  /usr/lib/x86_64-linux-gnu/libpthread.a

```
Output: reply.wav audio file with synthesized speech.

##  Java Web Frontend

- Open `java-web/index.html` in your browser.
- Uses **Java WebSocket client** to connect with the local **C++ backend**.
- Supports:
  - ğŸ¤ Microphone input
  - ğŸ§  Real-time AI response display
  - ğŸ”Š Audio playback of AI-generated reply

---

##  Android Client

- Import `android-client/` into **Android Studio**.
- Update the backend server IP address (`192.168.x.x`).
- Build and run on **Android 8.0+** devices.
- Features:
  - ğŸ¤ Voice input
  - ğŸ’¬ Text response display
  - ğŸ”Š Audio playback

---

##  Notes

- This project is currently a **prototype and module testbed**.
- Models are **not yet integrated into a unified backend server**.
- Each component is designed for **independent testing**.
- Integration and orchestration are left to the user for **custom development**.

---

## âœ Author Note

- All **C++ test code**, **installation scripts**, and **communication logic** were developed by the author.
- The goal is to demonstrate **fully offline AI voice interaction** using **open-source models**.
- Contributions, forks, and custom adaptations are welcome.

---

##  License

This project is released under the **MIT License**.

Each AI model follows its respective original license:

| Model      | Source                                         | License     |
|------------|------------------------------------------------|-------------|
| **Vosk**   | [https://github.com/alphacep/vosk-api/releases](https://github.com/alphacep/vosk-api/releases)             | Apache 2.0  |
| **TinyLLaMA** | [https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF](https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF) | MIT         |
| **Piper**  | [https://github.com/rhasspy/piper?tab=readme-ov-file](https://github.com/rhasspy/piper?tab=readme-ov-file)       | MIT         |


## Contact

For questions or collaboration requests, please open a GitHub issue or fork the project.


---

### ğŸ”§ Optional Additions

If you want, I can also provide:

- `.gitignore` for C++/Java/Android projects  
- `LICENSE` file (MIT)  
- `CONTRIBUTING.md` template  
- Badges (for GitHub Actions, License, etc.)

Let me know if you'd like to include those.

---



















